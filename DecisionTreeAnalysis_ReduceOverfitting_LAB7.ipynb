{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSU DS 200 \n",
    "# Lab 7A Evaluate Decision Trees and Understand Risk of Overfitting\n",
    "## Learning Objectives \n",
    "\n",
    "In this lab, you will learn to be able to do the following:\n",
    "- Learn to evaluate a predictive model regarding \"how good is the model\"\n",
    "    * In particular, you will learn how to interpret \"confusion matrix\".\n",
    "    * You will also learn how to identify \"strength\" and \"weakness\" of a predictive model from confusion matrix.\n",
    "- You will gain a hands-on understanding about the important risk of a model's \"overfitting\" to \n",
    "training data (using NFL pass prediction problem and data) by comparing a model's prediction\n",
    "performance for training data with that of testing data.\n",
    "- You will also be able to compare the overfitting risk of two predictive models by comparing their prediction performance with their model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data for Constructing a Predictive Model\n",
    "### Format of the Data\n",
    "Data for constructing a predictive model is often stored in a \"Comma-Separated Values\" format, also commonly referred to as \"CSV\" format.  A file that stores data in CSV format uses \".csv\" as its file extension.  \n",
    "\n",
    "### Read_CSV in Panda\n",
    "The easiest way to read a CSV file for the purpose of constructing a predictive model is to use read_csv function in Panda. The function reads data from a CSV file, and generates a table-style internal representation (called DataFrame).\n",
    "<ul>\n",
    "    <li> The first parameter of the function is the name of the csv file to be read. </li>\n",
    "\n",
    "    <li> The \"sep=\" parameter in read_csv specifieds the separator of different fields.  Because the CSV file used for this lab uses comma (i.e., \",\") as separator, the read_csv function has \"sep=\",\" as the second pamater. </li>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ben_pass= pd.read_csv('Ben-NE-9-10-2015-pass-6-1.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the Data \n",
    "The first row of the CSV file contains the names of attributes/features for each passing play of a specific NFL game (between Pittsburgh Steelers and New England Patriots held on September 10th, 2015).  Because pass prediction model for each quaterback can be different, so this dataset is prepared for the purpose of predicting the outcome of passing play by Steeler quaterback Ben Rothlisberger. The last column of the CSV file contains the outcome of each passing play.\n",
    "\n",
    "In general, the data for building a predictive model involves two types: \n",
    "<ol>\n",
    "    <li> The input data to the model (which we also call FEATURES), and </li>\n",
    "    <li> The DESIRED prediction output data of the model (for each corresponding input) </li>\n",
    "    </ol>\n",
    "Together, these data are used to \"train\" the model, as we shall see later, so that the model's output,\n",
    "given each input, is AS CLOSE AS POSSIBLE (we will elaborate this point later) to the DESIRED output.\n",
    "\n",
    "For example, the data for training to predict pass completion includes input data for the prediction (e.g., distance of pass, number of down, yards to go, etc), and the DESIRED output of the prediction (i.e., whether a pass plays completes or not). \n",
    "\n",
    "The meaning of all the input attributes/features for this lab are listed below:\n",
    "<ul>\n",
    "    <li>down: The number of down for the play</li>\n",
    "    <li>ydstogo: The remaining yards needed to gain for a first down</li>\n",
    "    <li>Yards.Gained.PrevPlay: The number of yards gained in the previous play (which can be a run play or passing play}</li>\n",
    "    <li>AirYards: The distance between the starting position of the play and the receiving position of the passing play. A negative number means the quarterback moves back in the play such that the net yardage gain, if the pass completes, is negative. </li>\n",
    "    <li>PassLocation: The area of passing location: -1 means left field, 0 means center field, 1 means right field. </li>\n",
    "</ul>\n",
    "\n",
    "The value of the desired prediction output (i.e., PassOutcome in the last column) in the dataset indicates whether the outcome of each passing play, represented by each row, is completes (i.e., having the value \"1\") or incomplete (i.e., having the value \"0\").  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    down  ydstogo  Yards.Gained.PrevPlay  AirYards  PassLocation  PassOutcome\n",
      "0      1       10                     18        -4             1            1\n",
      "1      1       10                      0         9             1            1\n",
      "2      3       22                      6         1             1            1\n",
      "3      1       10                      0         7            -1            1\n",
      "4      1       10                     13         6            -1            1\n",
      "5      1       10                     12         7            -1            1\n",
      "6      1       10                      0         5             1            0\n",
      "7      2       10                      0        25             1            0\n",
      "8      3        5                     -1         6            -1            1\n",
      "9      1       15                      4        -1             1            1\n",
      "10     3       18                     -6        17            -1            1\n",
      "11     1       20                      5         5            -1            1\n",
      "12     2       11                      9         4            -1            1\n",
      "13     2       13                     -3        -2            -1            1\n",
      "14     3        6                      7         6             0            1\n",
      "15     2        7                      0        11             1            1\n",
      "16     1       10                     13        16             1            1\n",
      "17     1       10                     19         6             1            1\n",
      "18     2        8                      2         0            -1            0\n",
      "19     3        8                      0        39            -1            1\n",
      "20     3        3                      1        19             1            0\n",
      "21     1       10                      0        11             0            1\n",
      "22     2       10                      0        17            -1            1\n",
      "23     1       10                     18         7             0            1\n",
      "24     1        9                      2         4            -1            1\n",
      "25     2        6                      3         6             0            1\n",
      "26     1       10                      0         5             1            1\n",
      "27     2       15                      9         4            -1            1\n",
      "28     3        6                      9        26             1            1\n",
      "29     2        8                      2         0            -1            1\n",
      "..   ...      ...                    ...       ...           ...          ...\n",
      "40     2       15                     -5         7             0            1\n",
      "41     3        6                     -1         2            -1            1\n",
      "42     1       10                      0        25             1            1\n",
      "43     2        5                      5         2             1            1\n",
      "44     2        8                      0         1             1            1\n",
      "45     1        1                      0         1             0            0\n",
      "46     1       10                      0        18             1            1\n",
      "47     1       10                      0        27             0            0\n",
      "48     3        5                      5         4             0            1\n",
      "49     2        1                      0         1             1            0\n",
      "50     3        1                      0         1            -1            1\n",
      "51     2        3                      7         9             0            0\n",
      "52     3        3                      0         9             1            0\n",
      "53     2       12                     -2        23             1            0\n",
      "54     3       12                      0         6             0            0\n",
      "55     1       10                      0        18             1            1\n",
      "56     1       10                     18        39            -1            0\n",
      "57     2        9                      1         7            -1            1\n",
      "58     3        4                      3        -3             1            0\n",
      "59     1       10                      0        11             1            0\n",
      "60     2       10                      0         4            -1            1\n",
      "61     3        1                      9         6             0            1\n",
      "62     1       10                      0        29             0            0\n",
      "63     2       10                      0         1            -1            1\n",
      "64     3        8                      2        13             0            1\n",
      "65     2       27                     -7        14             0            1\n",
      "66     3        9                      0        12            -1            0\n",
      "67     4        9                      0        15            -1            1\n",
      "68     1       10                      0        11            -1            1\n",
      "69     1       10                     11        11            -1            1\n",
      "\n",
      "[70 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Ben_pass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Labelled Data for Model Training\n",
    "In order to use the data to train a predictitive model, we need to extract the input data and corresponding output data from the table-like internal representation (i.e., DataFrame) generated by Panda read_csv function (and subsequentenly assigned to the variable Ben_pass).  \n",
    "\n",
    "One easy way to do this is to use .values method (of DataFrame) to \n",
    "<ol>\n",
    "    <li> Extract values from the columns for the input data and assign it to a variable (e.g., \"X\" in the code below), and </li>\n",
    "    <li> Extract values from the column for the DESIRED output data and assigned to a different variable (e.g., \"Y\" in the code below).</li>\n",
    "</ol>\n",
    "\n",
    "### Prepare Input Data for Model Training\n",
    "\n",
    "We want to use the following five attributes as inputs for predicting pass completion:\n",
    "<ul>\n",
    "    <li> down: The number of down for the play </li>\n",
    "    <li> ydstogo: The remaining yards needed to gain for a first down </li>\n",
    "<li> Yards.Gained.PrevPlay: The number of yards gained in the previous play (which can be a run play or passing play} </li>\n",
    "<li> AirYards: The distance between the starting position of the play and the receiving position of the passing play. A negative number means the quarterback moves back in the play such that the net yardage gain, if the pass completes, is negative. </li>\n",
    "<li>PassLocation: The area of passing location: -1 means left field, 0 means center field, 1 means right field.</li>\n",
    "    </ul>\n",
    "\n",
    "In DataFrame, the first column is referred to as column \"0\" (rather than column 1).  Therefore, the columns of the table-like representation stored in Ben_pass are:\n",
    "<ul>\n",
    "    <li> The column\n",
    "        storing the value of \"down\" is column 0. </li>\n",
    "    <li> The column storing the value of \"ydstogo\" is column 1. </li>\n",
    "    <li> The column storing the value of \"Yards.Gained.PrevPlay\" is column 2. </li>\n",
    "    <li> The column storing the value of \"AirYards\" is column 3. </li>\n",
    "    <li> The column storing the value of \"PassLocation\" is column 4. </li>\n",
    "    <li> The column storing the value of desired model output \"PassOutcome\" is column 5. </li>\n",
    "    </ul>\n",
    "\n",
    "#### As we saw in Lab 5, to extract column 0, 1, 2, 3, and 4 from Ben_pass (which stores the table-like representation), we use \"0:5\" to indicate a range of columns from column 0 to (but NOT including) column 5. \n",
    "\n",
    "We store the extracted input data in a variable called X.\n",
    "\n",
    "#### Notice that we do not want to extract column 5 because it contains the desired model output, so we want to save it in a different variable to prepare for model training (which takes model input data and desired model output data separately)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 10 18 -4  1]\n",
      " [ 1 10  0  9  1]\n",
      " [ 3 22  6  1  1]\n",
      " [ 1 10  0  7 -1]\n",
      " [ 1 10 13  6 -1]\n",
      " [ 1 10 12  7 -1]\n",
      " [ 1 10  0  5  1]\n",
      " [ 2 10  0 25  1]\n",
      " [ 3  5 -1  6 -1]\n",
      " [ 1 15  4 -1  1]\n",
      " [ 3 18 -6 17 -1]\n",
      " [ 1 20  5  5 -1]\n",
      " [ 2 11  9  4 -1]\n",
      " [ 2 13 -3 -2 -1]\n",
      " [ 3  6  7  6  0]\n",
      " [ 2  7  0 11  1]\n",
      " [ 1 10 13 16  1]\n",
      " [ 1 10 19  6  1]\n",
      " [ 2  8  2  0 -1]\n",
      " [ 3  8  0 39 -1]\n",
      " [ 3  3  1 19  1]\n",
      " [ 1 10  0 11  0]\n",
      " [ 2 10  0 17 -1]\n",
      " [ 1 10 18  7  0]\n",
      " [ 1  9  2  4 -1]\n",
      " [ 2  6  3  6  0]\n",
      " [ 1 10  0  5  1]\n",
      " [ 2 15  9  4 -1]\n",
      " [ 3  6  9 26  1]\n",
      " [ 2  8  2  0 -1]\n",
      " [ 3  3  5 23  1]\n",
      " [ 4  3  0  4  0]\n",
      " [ 2  5  5 26 -1]\n",
      " [ 3  5  0  7  0]\n",
      " [ 1 10  0  4  1]\n",
      " [ 3  5  1  5  1]\n",
      " [ 2  1  9 -1 -1]\n",
      " [ 2  1  0  0 -1]\n",
      " [ 1 10 28 23 -1]\n",
      " [ 1 10 13 -5 -1]\n",
      " [ 2 15 -5  7  0]\n",
      " [ 3  6 -1  2 -1]\n",
      " [ 1 10  0 25  1]\n",
      " [ 2  5  5  2  1]\n",
      " [ 2  8  0  1  1]\n",
      " [ 1  1  0  1  0]\n",
      " [ 1 10  0 18  1]\n",
      " [ 1 10  0 27  0]\n",
      " [ 3  5  5  4  0]\n",
      " [ 2  1  0  1  1]\n",
      " [ 3  1  0  1 -1]\n",
      " [ 2  3  7  9  0]\n",
      " [ 3  3  0  9  1]\n",
      " [ 2 12 -2 23  1]\n",
      " [ 3 12  0  6  0]\n",
      " [ 1 10  0 18  1]\n",
      " [ 1 10 18 39 -1]\n",
      " [ 2  9  1  7 -1]\n",
      " [ 3  4  3 -3  1]\n",
      " [ 1 10  0 11  1]\n",
      " [ 2 10  0  4 -1]\n",
      " [ 3  1  9  6  0]\n",
      " [ 1 10  0 29  0]\n",
      " [ 2 10  0  1 -1]\n",
      " [ 3  8  2 13  0]\n",
      " [ 2 27 -7 14  0]\n",
      " [ 3  9  0 12 -1]\n",
      " [ 4  9  0 15 -1]\n",
      " [ 1 10  0 11 -1]\n",
      " [ 1 10 11 11 -1]]\n"
     ]
    }
   ],
   "source": [
    "X= Ben_pass.values[:,0:5]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Output Data for Model Training\n",
    "To prepare desired output data (also referred to as target output data) for model training, we extract PassOutcome, which is stored in column 5 of Ben_pass table-like representation.  Similar to the previous step, we extract this data from ALL ROWS of the Ben_pass table-like representation. \n",
    "\n",
    "We store this output data in a variable Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "Y= Ben_pass.values[:,5]\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the result of print(Y), Y is a one-dimensional array.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Decision Tree from a Set of Training Data\n",
    "\n",
    "### Like Lab 5, we will use Python scikit-learn module to create a decision tree.\n",
    "### Scikit-learn offers other machine learning models beyond decision trees.\n",
    "### We do not need to install scikit-learn, because it has been pre-installed in Azure Notebooks (together with Python 3)\n",
    "Scikit-learn (sklearn) is a Python module that contains many useful machine learning code, including code for constructing model from data, for creating predictive models using multiple machine learning methods (including decision tree which we will use), and for evaluating how good is the model created.  \n",
    "\n",
    "### In the beginning of this notebook, we used the following import statement to import a submodule of scikit-learn (sklearn), tree (which provides functions/methods related to decision trees)\n",
    "    from sklearn import tree\n",
    "\n",
    "### Split the Data into Training Set and Testing Set using Train_Test_Split in sklearn\n",
    "It is important that we reserve some data to evaluate how good is the prediction capability of the model.  This means that we are NOT going to use this reserved data to train the model.  THIS IS A VERY IMPORTANT POINT and we will return to it later for a more detail look.  For now, we will focus on the workflow for constructing a predictive model.\n",
    "\n",
    "There are multiple ways to use data to train decision tree models.  We will use train_test_split Python command from sklearn Python module. In the beginning of this lab, we have imported train_test_split from sklearn as follows:\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "Importing a function from a library means we can directly use this function after the import.\n",
    "\n",
    "Train_test_split has four parameters:\n",
    "<ol>\n",
    "    <li> The first paraemter is all of the model's input data. We have prepared variable X1 to be used here. </li>\n",
    "    <li> The second parameter is all of the model's target output data.  We have prepared variable Y to be used here. </li>\n",
    "    <li> The third parameter (test_size) is the percentage of the data (both model input and output) to be RESERVED for testing.  We use 25% here, and will revisit this topic later. </li>\n",
    "    <li> The fourth paraemter (randome_state) is a random number to be used to randomly split the model's input and output data (i.e., the data stored in variable X and variable Y) into two subgroups: a Training Set and a Testing Set.\n",
    "    </li></ol>\n",
    "\n",
    "The output of the train_test_split function includes four inter-related results:\n",
    "<ol>\n",
    "    <li> The Model Input Data (features) used for Training: We store this in the variable X_train </li>\n",
    "    <li> The Model Input Data (features) used for Testing: We store this in the variable X_test </li>\n",
    "    <li> The Model Output Data (prediction) used for Training: We store this in the variable y_train </li>\n",
    "    <li> The Model Output Data (prediction) used for Testing: We store this in the variable y_test </li>\n",
    "    \n",
    "    </ol>\n",
    "    \n",
    "### In this lab, we will split the data into training and testing through a 80% - 20% split.  As we will see later, this is one of the most common ways for splitting labelled data.\n",
    "\n",
    "### Self-evaluation\n",
    "You may notice the input to train_test_split is \"X\" here, rather than \"X1\" in Lab 5.  Do you know why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.20, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 10 13 -5 -1]\n",
      " [ 1 10  0  5  1]\n",
      " [ 1 10 18  7  0]\n",
      " [ 1 10 18 39 -1]\n",
      " [ 1 10 28 23 -1]\n",
      " [ 3  8  2 13  0]\n",
      " [ 1 10  0 18  1]\n",
      " [ 1 20  5  5 -1]\n",
      " [ 2  8  2  0 -1]\n",
      " [ 3  4  3 -3  1]\n",
      " [ 2 27 -7 14  0]\n",
      " [ 1 10 12  7 -1]\n",
      " [ 3  3  1 19  1]\n",
      " [ 1 10 11 11 -1]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We also imported DecisionTreeClassifier from the tree submodule in sklearn:\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "### Using DecisionTreeClassifier to Train a Decision Tree\n",
    "There are two steps involved in creating a decision tree using DecisionTreeClassifier.\n",
    "1. Create an \"empty\" Decision Tree Classifier by specifying the various parameters we use to construct the decision tree. Save the created empty Decision Tree Classifier in a variable (e.g., \"clf\" in the code below) for the next step. Some of the important parameters are the following:\n",
    "    * criterion: We will use 'entropy' as the criteria for creating decision trees in this class.  \n",
    "    * max_depth: This parameter specifies how \"deep\" the decision tree is allowed.  If you choose \"max_depth=3\", the tree created will be limited to 3 levels. (The root node is at level 0.) As we will see later, the choice of this parameter can affect the model's risk for overfitting.\n",
    "    * min_samples_leaf: This parameter specifies the minimum number of samples required in a leaf node. As we will see later, the choice of this parameter can also affect the model's risk for overfitting.\n",
    "2. Use a set of input training data and output training data to \"train\" the Decision Tree Classifier (previously \"empty\" one; but will have an actual Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1 Train a Decision Tree (Model A) with a High Overfitting Risk (3 points)\n",
    "In Lab 5, we chose the parameters of max_depth and min_samples_leaf.  In this lab,\n",
    "we first intentionally create a decision tree with a high overfitting risk.\n",
    "\n",
    "Fill in a large number for the parameters of max_depth (e.b., between 10 and 20) and \n",
    "set the min_samples_leaf to be 1. \n",
    "\n",
    "We will refer to this model you build as \"Model A\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=15,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=100,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = DecisionTreeClassifier(criterion = 'entropy', random_state = 100,\n",
    "                               max_depth=15, min_samples_leaf=1)\n",
    "clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the code below to visualize the decision tree. The only thing you need to fill in is the name of the 5th feature you used for input.  Replace '???' with a string of that feature name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data1= tree.export_graphviz(clf1, out_file=None, feature_names=('down','ydstogo','YardsGainedPrevPlay','AirYards','PassLocation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<graphviz.files.Source at 0x7fcc2e6de9b0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = graphviz.Source(dot_data1)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save the visualization of decision tree in a PDF file using graph.render command below. Replace '????' with the name of the file you want to use for the PDF file (without the .pdf extension).  After executing the code below with the file name, you should be able to find the file (with .pdf extension) in the same Project folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dtree.pdf'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.render('dtree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 Evaluating Overfitting Risk of a Decision Tree Model (Model A) (5 points)\n",
    "One way to understand the concept of \"overfitting\" for a decision tree (or other types of\n",
    "machine learning model) is to see how the model's prediction performance of the training data \n",
    "compare with the prediction performance of testing data.\n",
    "- (1) Uses the model (i.e., the decision tree learned) to predict pass completion for the training data. Generate the confusion matrix of the prediction results, and explain what it means (e.g., what are true positive, false positive, true negative, false negative). \n",
    "#### See the next text cell for instructions on interpreting confusion matrix\n",
    "- (2) Use the model (i.e., the decision tree learned) to predict pass completion for the testing data. Generate the confusion matrix of the prediction results, and explain what it means. \n",
    "- (3) What is your hypothesis that may explain the significant difference between the prediction performance for the training data and the testing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Exercise 2:\n",
    "- (1) False Positive: 0, True Positive: 41 , True Negative: 15 , False Negative: 0\n",
    "- (2) False Positive: 4, True Positive: 9 , True Negative: 0 , False Negative: 1\n",
    "- (3) The reason that the training data is different than the testing data because when new data is introduced to the already trained prediction model, the output values will change. You can't use training data to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_training1=clf1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        15\n",
      "          1       1.00      1.00      1.00        41\n",
      "\n",
      "avg / total       1.00      1.00      1.00        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, prediction_training1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  0],\n",
       "       [ 0, 41]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_train, prediction_training1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret Confusion Matrix\n",
    "\n",
    "One of the effective and convenient ways to evaluate the prediction performance of a predictive model (whether the model is a decision tree or of other types) is to use confusion matrix.  Sklearn module\n",
    "in Python includes a submodule called \"metrics\", one of the functions provided by the submodule is\n",
    "confusion_matrix, which takes two parameters:\n",
    "- the first parameter is the correct/desired output\n",
    "- the second parameter is the prediction output generated by a model.\n",
    "\n",
    "The output of confusion_matrix is a 2x2 array (often referred to as \"confusion matrix\"), such as \n",
    "the one you just generated above.\n",
    "- The first row of the matrix corresponds to DESIRED/ACTUAL negative class (e.g., actual incomplete passes)\n",
    "- The second row of the matrix corresponds to DESIRED/ACTUAL positive class (e.g., actual complete passes)\n",
    "- The first column of the matrix corresponds to PREDICTED negative class (e.g., predicted incomplete passes)\n",
    "- The second column of the matrix corresponds to PREDICTED positive class (e.g., predicted complete passes).\n",
    "\n",
    "- Each entry in the array represents the total number of data with the corresponding predicted class and actual class. We also give each of them a more meaningful name:\n",
    "- row 1, column 1: True Negative (correctly predicted negative class)\n",
    "- row 1, column 2: False Positive (incorrect positive predictions, actually they are negative class)\n",
    "- row 2, column 1: False Negative (incorrect negative predictions, actually they are positive class) \n",
    "- row 2, column 2: True Positive (correctly predicted positive class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_testing1 = clf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(prediction_testing1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 1 1 1 1 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         4\n",
      "          1       0.69      0.90      0.78        10\n",
      "\n",
      "avg / total       0.49      0.64      0.56        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, prediction_testing1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 4],\n",
       "       [1, 9]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, prediction_testing1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare two models regarding their overfitting risk\n",
    "\n",
    "In order to have a fair comparison of two models regarding their overfitting risk, it is VERY important that we use the SAME set of training data and testing data.  Otherwise, one model may perform better than the other model because its testing data is \"easier\".  \n",
    "\n",
    "We will construct a model with different parameters for a simpler decision tree, we will refer to this model as \"Model B\". We will then compare model B's performance and model complexity with model A's performance and model complexity regarding their overfitting risk.\n",
    "\n",
    "### Exercise 3 Train a simpler Decision Tree (3 points)\n",
    "Choose a max_depth between 5 and 6, set min_sample_leaf to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=5,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=2, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=100,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = DecisionTreeClassifier(criterion = 'entropy', random_state = 100,\n",
    "                               max_depth=5, min_samples_leaf=2)\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data2= tree.export_graphviz(clf2, out_file=None, feature_names=('down','ydstogo','YardsGainedPrevPlay','AirYards','PassLocation'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<graphviz.files.Source at 0x7fcc2e6de748>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = graphviz.Source(dot_data2)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seconddecsiontree.pdf'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.render('Seconddecsiontree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_training2=clf2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(prediction_training2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.73      0.73        15\n",
      "          1       0.90      0.90      0.90        41\n",
      "\n",
      "avg / total       0.86      0.86      0.86        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_train, prediction_training2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  4],\n",
       "       [ 4, 37]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_train, prediction_training2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_testing2 = clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 0 0 1 1 1 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(prediction_testing2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 1 1 1 1 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.50      0.50         4\n",
      "          1       0.80      0.80      0.80        10\n",
      "\n",
      "avg / total       0.71      0.71      0.71        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, prediction_testing2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2],\n",
       "       [2, 8]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, prediction_testing2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4 Compare Two Models Regarding Overfitting Risk and Prediction Performance (9 points)\n",
    "\n",
    "Based on the prediction performance of the second model (Model B), compare it with the prediction performance of the first model (Model A) by answering the following questions:\n",
    "- (1) How does the prediction performance of Model B compared to Model A for TRAINING DATA?\n",
    "- (2) How does the prediction performance of Model B compared to Model A for TESTING DATA?\n",
    "- (3) Which model will you choose?\n",
    "- (4) What do you think cause model A to predict worse than model B for testint data?\n",
    "- (5) What lessons did you learn regarding ways to reduce the risk of overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to Exercise 4\n",
    "- (1) The prediction performance for training data of 'model A' is better than 'model B' because 'Model A' has 56 true values, while 'Model B' only has 48\n",
    "- (2)The prediction performance for testing data of 'model B' is better than 'model A' because 'Model B' has 9 true values, while 'Model A' only has 8\n",
    "- (3) I will chose 'Model B' because the testing data is better to use than training data and Model 'B' has more true values\n",
    "- (4) Model A predicts worse than model B because when new data is introduced to model a it handles the data worse than model b. Model A is fit to close to the data while model b can be generalized to new data better.\n",
    "- (5) I learned that using testing data is better than using training data to compare values. I also learned that the model should not be fit to close to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
